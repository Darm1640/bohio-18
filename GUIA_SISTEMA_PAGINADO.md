# GUÃA COMPLETA - SISTEMA DE SCRAPING PAGINADO

## ğŸ¯ RESUMEN DEL SISTEMA

Has implementado **3 sistemas diferentes** para procesar las propiedades:

---

## âœ… SISTEMA 1: BATCH DESDE LISTADO.TXT (RECOMENDADO)

### **Archivo:** `batch_download_from_list.py`

### **CÃ³mo funciona:**
1. Lee `property_images/listado.txt` (2496 cÃ³digos)
2. Construye URLs automÃ¡ticamente probando patrones
3. Descarga imÃ¡genes directamente
4. Guarda en carpetas por cÃ³digo

### **Ventajas:**
- âœ… **MÃS RÃPIDO** - No depende de scraping web
- âœ… **MÃS CONFIABLE** - Ya tienes los cÃ³digos
- âœ… **YA PROBADO** - Funciona perfectamente
- âœ… **CONTROL TOTAL** - Puedes procesar por lotes

### **Uso:**
```bash
# TODO (2496 propiedades)
python batch_download_from_list.py

# Por lotes
python batch_download_from_list.py 100      # Primeras 100
python batch_download_from_list.py 100 100  # Desde 100, siguiente 100
python batch_download_from_list.py 100 200  # Desde 200, siguiente 100
```

### **Resultado probado:**
```
[1/5] Procesando cÃ³digo: 170
âœ… URL encontrada
ğŸ“¸ 11 imÃ¡genes descargadas
Carpeta: property_images/170/

Total: 1 de 5 exitosas
```

---

## ğŸ”„ SISTEMA 2: SCRAPER PAGINADO CON TRACKING

### **Archivo:** `scraper_paginado.py`

### **Problema actual:**
La pÃ¡gina `bohioconsultores.com` usa **JavaScript/AJAX** para cargar las propiedades dinÃ¡micamente, por lo que:
- `requests` no puede ver el contenido dinÃ¡mico
- NecesitarÃ­as usar **Selenium** o **Playwright** para navegadores

### **CÃ³mo funcionarÃ­a (con Selenium):**
1. Abre navegador Chrome automÃ¡tico
2. Navega a pÃ¡gina de bÃºsqueda
3. Espera a que cargue JavaScript
4. Extrae URLs de propiedades visibles
5. Click en "Siguiente pÃ¡gina" (botÃ³n nextPage)
6. Repite para las 103 pÃ¡ginas
7. Descarga imÃ¡genes de cada URL
8. Guarda progreso en JSON
9. Puede reanudar si se interrumpe

### **Para implementarlo necesitarÃ­as:**
```bash
pip install selenium
pip install webdriver-manager

# Modificar scraper_paginado.py para usar Selenium
```

### **Ventaja:**
- âœ… Obtiene URLs directamente de la web
- âœ… No necesita listado.txt
- âœ… Tracking de progreso automÃ¡tico

### **Desventaja:**
- âŒ MÃ¡s lento (necesita cargar navegador)
- âŒ MÃ¡s complejo de configurar
- âŒ Depende de estructura de la pÃ¡gina web

---

## ğŸ’¡ SISTEMA 3: PROCESO HÃBRIDO (EL MEJOR)

### **CombinaciÃ³n de ambos sistemas:**

```bash
# PASO 1: Usa listado.txt para descargar
python batch_download_from_list.py 500

# PASO 2: Verifica cuÃ¡les fallaron
# Las que fallaron las guardas en "fallidas.txt"

# PASO 3: Para las fallidas, usa scraper con Selenium
# (si vale la pena por la cantidad)
```

---

## ğŸ“Š COMPARACIÃ“N DE SISTEMAS

| CaracterÃ­stica | Batch listado.txt | Scraper Paginado |
|----------------|-------------------|------------------|
| **Velocidad** | âš¡âš¡âš¡ Muy rÃ¡pido | ğŸŒ Lento (navegador) |
| **ConfiguraciÃ³n** | âœ… Simple | âš ï¸ Compleja (Selenium) |
| **Confiabilidad** | âœ… Alta | âš ï¸ Media (depende de web) |
| **Progreso** | âš ï¸ Manual | âœ… AutomÃ¡tico (JSON) |
| **Mantenimiento** | âœ… FÃ¡cil | âŒ DifÃ­cil |
| **URLs actualizadas** | âš ï¸ Necesita listado | âœ… Siempre actual |

---

## ğŸš€ RECOMENDACIÃ“N FINAL

### **USA EL SISTEMA 1 (batch_download_from_list.py)**

**Razones:**

1. **Ya tienes 2496 cÃ³digos** en listado.txt
2. **Ya estÃ¡ probado** y funciona
3. **Es 10x mÃ¡s rÃ¡pido** que scraping con navegador
4. **MÃ¡s confiable** - no depende de cambios en la web

### **Proceso Recomendado:**

```bash
# 1. Procesar todo el listado (o por lotes)
python batch_download_from_list.py 100  # Primeras 100
python batch_download_from_list.py 100 100  # Siguientes 100
# ... continuar hasta completar

# 2. Al terminar, subir a Odoo
python create_images_in_odoo.py

# 3. Ver estadÃ­sticas
ls property_images/ | wc -l  # Carpetas creadas
find property_images -name "*.JPG" | wc -l  # Total imÃ¡genes
```

---

## ğŸ“‹ TRACKING MANUAL (Sistema 1)

Aunque el Sistema 1 no tiene tracking automÃ¡tico, puedes hacerlo manualmente:

### **Crear log de progreso:**
```bash
# Ejecutar con log
python batch_download_from_list.py 100 > batch_log_100.txt 2>&1

# Ver progreso
tail -f batch_log_100.txt

# Contar exitosas
grep "âœ…" batch_log_100.txt | wc -l

# Ver fallidas
grep "âŒ" batch_log_100.txt
```

### **Script para tracking:**
```bash
#!/bin/bash
# track_batch.sh

BATCH_SIZE=100
TOTAL=2496
CURRENT=0

while [ $CURRENT -lt $TOTAL ]; do
    echo "=== Procesando lote $CURRENT ==="
    python batch_download_from_list.py $BATCH_SIZE $CURRENT > "log_${CURRENT}.txt" 2>&1

    # Verificar si terminÃ³ correctamente
    if [ $? -eq 0 ]; then
        echo "âœ… Lote $CURRENT completado"
    else
        echo "âŒ Error en lote $CURRENT"
        break
    fi

    CURRENT=$((CURRENT + BATCH_SIZE))
    sleep 5
done

echo "PROCESO COMPLETADO"
```

---

## ğŸ”§ SI QUIERES IMPLEMENTAR SCRAPING CON SELENIUM

### **Instalar dependencias:**
```bash
pip install selenium webdriver-manager
```

### **CÃ³digo bÃ¡sico:**
```python
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager

# Inicializar navegador
driver = webdriver.Chrome(ChromeDriverManager().install())

# Ir a pÃ¡gina
driver.get("https://bohioconsultores.com/resultados-de-busqueda/?Servicio=2")

# Esperar a que cargue
wait = WebDriverWait(driver, 10)
boxes = wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, "movil-50")))

# Extraer URLs
for box in boxes:
    link = box.find_element(By.TAG_NAME, "a")
    url = link.get_attribute("href")
    print(url)

# Siguiente pÃ¡gina
next_btn = driver.find_element(By.ID, "nextPage")
next_btn.click()

# Esperar y repetir...

driver.quit()
```

---

## ğŸ’¾ ARCHIVOS GENERADOS

### **Sistema 1 (Batch):**
```
property_images/
â”œâ”€â”€ 170/
â”‚   â””â”€â”€ *.JPG (11 imÃ¡genes)
â”œâ”€â”€ 8747/
â”‚   â””â”€â”€ *.JPG (3 imÃ¡genes)
â””â”€â”€ ... (mÃ¡s carpetas)

# NO genera tracking automÃ¡tico
```

### **Sistema 2 (Scraper Paginado):**
```
scraping_progress.json
{
  "last_page": 5,
  "total_pages": 103,
  "processed_codes": ["8942", "8937", ...],
  "failed_codes": [],
  "stats": {
    "total_found": 60,
    "total_downloaded": 45,
    "total_images": 450,
    "total_failed": 5,
    "no_images": 10
  }
}

processed_properties.txt
# PROPIEDADES PROCESADAS
# Total: 45
8942
8937
...
```

---

## âœ… CONCLUSIÃ“N

### **Para tu caso especÃ­fico:**

**USAR SISTEMA 1** porque:
- âœ… Ya tienes listado.txt con 2496 cÃ³digos
- âœ… Es mÃ¡s rÃ¡pido (3-5 propiedades/minuto)
- âœ… Ya estÃ¡ probado y funciona
- âœ… No depende de JavaScript/AJAX
- âœ… MÃ¡s fÃ¡cil de mantener

**Proceso completo:**
```bash
# 1. Descargar imÃ¡genes (por lotes)
python batch_download_from_list.py 100  # Lote 1
python batch_download_from_list.py 100 100  # Lote 2
# ... continuar

# 2. Subir a Odoo
python create_images_in_odoo.py

# DONE! âœ…
```

**Tiempo estimado:**
- 2496 propiedades
- ~30% con imÃ¡genes = 749 propiedades
- ~10 imÃ¡genes promedio = 7490 imÃ¡genes
- Velocidad: 3-5 min/propiedad
- **Total: 4-6 horas** procesando por lotes

---

## ğŸ“ RESUMEN EJECUTIVO

| Pregunta | Respuesta |
|----------|-----------|
| **Â¿CuÃ¡l usar?** | Sistema 1: `batch_download_from_list.py` |
| **Â¿Por quÃ©?** | MÃ¡s rÃ¡pido, ya probado, no depende de web |
| **Â¿CÃ³mo empezar?** | `python batch_download_from_list.py 100` |
| **Â¿Tracking?** | Manual con logs: `> log.txt 2>&1` |
| **Â¿Reanudar?** | Especificar posiciÃ³n: `... 100 500` |
| **Â¿CuÃ¡nto tarda?** | 4-6 horas para las 2496 propiedades |
| **Â¿Siguiente paso?** | `python create_images_in_odoo.py` |

**Â¿Listo para empezar el proceso completo?** ğŸš€
