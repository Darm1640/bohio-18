#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script para descargar im√°genes en batch desde lista de c√≥digos de propiedades
Lee c√≥digos desde listado.txt y construye URLs autom√°ticamente
"""
import os
import sys
import io
import time
import requests
from bs4 import BeautifulSoup

# Importar la clase de descarga
sys.path.insert(0, os.path.dirname(__file__))
from download_property_images import PropertyImageDownloader


class BatchPropertyDownloader:
    """Descarga im√°genes de m√∫ltiples propiedades desde lista de c√≥digos"""

    def __init__(self, codes_file="property_images/listado.txt", output_dir="property_images"):
        self.codes_file = codes_file
        self.output_dir = output_dir
        self.downloader = PropertyImageDownloader(download_dir=output_dir)
        self.base_search_url = "https://bohioconsultores.com/resultados-de-busqueda/?Servicio=2"

    def read_property_codes(self):
        """Lee c√≥digos de propiedades desde listado.txt"""
        if not os.path.exists(self.codes_file):
            print(f"‚ùå Archivo no encontrado: {self.codes_file}")
            return []

        codes = []
        with open(self.codes_file, 'r', encoding='utf-8') as f:
            for line in f:
                code = line.strip()
                # Saltar primera l√≠nea si es encabezado
                if code and code != 'default_code' and not code.startswith('BOH-'):
                    # Extraer solo n√∫meros
                    if code.isdigit():
                        codes.append(code)
                    elif code.startswith('BOH-'):
                        # Extraer n√∫mero despu√©s de BOH-
                        parts = code.split('-')
                        if len(parts) > 1 and parts[1].isdigit():
                            codes.append(parts[1])

        return codes

    def construct_property_url(self, code):
        """
        Construye URL de propiedad desde c√≥digo
        Formato: https://bohioconsultores.com/detalle-propiedad/?Apartamento-en-Venta-[CODE]
        """
        # Intentar diferentes patrones comunes
        patterns = [
            f"https://bohioconsultores.com/detalle-propiedad/?Apartamento-en-Venta-{code}",
            f"https://bohioconsultores.com/detalle-propiedad/?Casa-en-Venta-{code}",
            f"https://bohioconsultores.com/detalle-propiedad/?Lote-en-Venta-{code}",
            f"https://bohioconsultores.com/detalle-propiedad/?Apartamento-en-Arriendo-{code}",
            f"https://bohioconsultores.com/detalle-propiedad/?Casa-en-Arriendo-{code}",
        ]
        return patterns  # Retornar todos los patrones para probar

    def fetch_search_page(self, page_number=1):
        """
        Obtiene p√°gina de b√∫squeda para extraer URLs reales
        Soporta navegaci√≥n por m√∫ltiples p√°ginas
        """
        try:
            # Construir URL con paginaci√≥n si es necesario
            url = self.base_search_url
            if page_number > 1:
                # Intentar diferentes formatos de paginaci√≥n
                separator = '&' if '?' in url else '?'
                url = f"{url}{separator}page={page_number}"

            print(f"\nüì• Obteniendo p√°gina de b√∫squeda (p√°gina {page_number})...")
            response = requests.get(url, timeout=15)
            response.raise_for_status()
            response.encoding = 'utf-8'
            return response.text
        except Exception as e:
            print(f"‚ùå Error obteniendo p√°gina de b√∫squeda: {e}")
            return None

    def extract_property_urls_from_search(self, html):
        """Extrae todas las URLs de propiedades desde p√°gina de b√∫squeda"""
        if not html:
            return []

        soup = BeautifulSoup(html, 'html.parser')
        urls = []

        # Buscar todos los enlaces que apuntan a detalle-propiedad
        for link in soup.find_all('a', href=True):
            href = link['href']
            if 'detalle-propiedad' in href:
                # Asegurar que sea URL completa
                if not href.startswith('http'):
                    href = f"https://bohioconsultores.com{href}"
                if href not in urls:
                    urls.append(href)

        return urls

    def scrape_all_pages(self, max_pages=10):
        """
        Navega m√∫ltiples p√°ginas de resultados para obtener todas las propiedades
        """
        print("\n" + "="*80)
        print("üîç NAVEGANDO P√ÅGINAS DE RESULTADOS DE B√öSQUEDA")
        print("="*80)

        all_urls = []
        page_number = 1

        while page_number <= max_pages:
            print(f"\nüìÑ Procesando p√°gina {page_number}/{max_pages}...")

            # Obtener HTML de la p√°gina
            html = self.fetch_search_page(page_number)
            if not html:
                print(f"‚ö†Ô∏è  No se pudo obtener p√°gina {page_number}, deteniendo...")
                break

            # Extraer URLs de propiedades
            urls = self.extract_property_urls_from_search(html)

            if not urls:
                print(f"‚ö†Ô∏è  No se encontraron propiedades en p√°gina {page_number}")
                if page_number == 1:
                    # Si no hay resultados en la primera p√°gina, algo est√° mal
                    print("‚ùå Error: No se encontraron resultados en la primera p√°gina")
                    break
                else:
                    # Si no hay m√°s resultados, hemos llegado al final
                    print("‚úÖ Fin de resultados alcanzado")
                    break

            # Filtrar URLs nuevas
            new_urls = [url for url in urls if url not in all_urls]
            all_urls.extend(new_urls)

            print(f"‚úÖ Encontradas {len(urls)} propiedades ({len(new_urls)} nuevas)")
            print(f"üìä Total acumulado: {len(all_urls)} propiedades")

            # Si no hay URLs nuevas, probablemente llegamos al final
            if not new_urls:
                print("‚úÖ No hay m√°s propiedades nuevas, finalizando...")
                break

            page_number += 1

            # Pausa entre p√°ginas para no sobrecargar el servidor
            if page_number <= max_pages:
                time.sleep(2)

        print(f"\n{'='*80}")
        print(f"üìä RESUMEN DE NAVEGACI√ìN")
        print(f"{'='*80}")
        print(f"   P√°ginas procesadas: {page_number - 1}")
        print(f"   Total URLs encontradas: {len(all_urls)}")
        print("="*80)

        return all_urls

    def process_all_properties(self, max_properties=None, start_from=0, max_pages=10):
        """
        Procesa todas las propiedades
        max_properties: l√≠mite de propiedades a procesar (None = todas)
        start_from: √≠ndice desde donde empezar
        max_pages: n√∫mero m√°ximo de p√°ginas de b√∫squeda a navegar
        """
        print("\n" + "="*80)
        print("BATCH DOWNLOADER - DESCARGA MASIVA DE IM√ÅGENES")
        print("="*80)

        # Opci√≥n 1: Leer c√≥digos desde listado.txt
        codes = self.read_property_codes()
        print(f"\nüìã C√≥digos encontrados en {self.codes_file}: {len(codes)}")

        urls = []
        if not codes:
            print("‚ö†Ô∏è  No se encontraron c√≥digos v√°lidos en listado.txt")
            print("üí° Intentando extraer desde p√°ginas de b√∫squeda...")

            # Opci√≥n 2: Extraer URLs navegando m√∫ltiples p√°ginas
            urls = self.scrape_all_pages(max_pages=max_pages)

            if urls:
                print(f"\n‚úÖ Total URLs encontradas: {len(urls)}")
            else:
                print("‚ùå No se pudieron obtener URLs de propiedades")
                return

        # Si tenemos URLs directas, usarlas
        # Si tenemos c√≥digos, intentar construir URLs
        if urls:
            # Ya tenemos URLs completas
            property_list = urls
        elif codes:
            # Tenemos c√≥digos, intentar construir URLs
            property_list = codes
        else:
            print("‚ùå No se encontraron propiedades para procesar")
            return

        # Aplicar l√≠mites
        if start_from > 0:
            property_list = property_list[start_from:]
            print(f"üîÑ Iniciando desde posici√≥n: {start_from}")

        if max_properties:
            property_list = property_list[:max_properties]
            print(f"üî¢ Limitando a: {max_properties} propiedades")

        print(f"\nüöÄ Procesando {len(property_list)} propiedades...")
        print("="*80)

        # Estad√≠sticas
        stats = {
            'total': len(property_list),
            'success': 0,
            'failed': 0,
            'no_images': 0,
            'total_images': 0,
            'failed_items': []
        }

        # Procesar cada propiedad
        for idx, item in enumerate(property_list, 1):
            print(f"\n[{idx}/{len(property_list)}] Procesando propiedad")
            print("-" * 80)

            success = False

            # Determinar si es URL o c√≥digo
            if isinstance(item, str) and item.startswith('http'):
                # Es una URL completa
                url = item
                print(f"üîó URL: {url}")

                try:
                    # Descargar im√°genes
                    result = self.downloader.process_property_url(url, download_locally=True)

                    if result and result.get('downloaded_images'):
                        stats['success'] += 1
                        stats['total_images'] += len(result['downloaded_images'])
                        print(f"‚úÖ {len(result['downloaded_images'])} im√°genes descargadas")
                        success = True
                    elif result:
                        stats['no_images'] += 1
                        print(f"‚ö†Ô∏è  Sin im√°genes")
                        success = True

                except Exception as e:
                    print(f"‚ùå Error: {e}")

                if not success:
                    stats['failed'] += 1
                    stats['failed_items'].append(url)

            else:
                # Es un c√≥digo, intentar construir URL
                code = item
                print(f"üî¢ C√≥digo: {code}")

                # Intentar con diferentes patrones de URL
                patterns = self.construct_property_url(code)

                for url_pattern in patterns:
                    try:
                        # Verificar si URL existe
                        test_response = requests.head(url_pattern, timeout=5, allow_redirects=True)

                        if test_response.status_code == 200:
                            print(f"‚úÖ URL encontrada: {url_pattern}")

                            # Descargar im√°genes
                            result = self.downloader.process_property_url(url_pattern, download_locally=True)

                            if result and result.get('downloaded_images'):
                                stats['success'] += 1
                                stats['total_images'] += len(result['downloaded_images'])
                                print(f"‚úÖ {len(result['downloaded_images'])} im√°genes descargadas")
                                success = True
                                break
                            elif result:
                                stats['no_images'] += 1
                                print(f"‚ö†Ô∏è  Sin im√°genes")
                                success = True
                                break

                    except requests.exceptions.RequestException:
                        # URL no v√°lida, probar siguiente patr√≥n
                        continue

                if not success:
                    stats['failed'] += 1
                    stats['failed_items'].append(code)
                    print(f"‚ùå No se pudo procesar c√≥digo: {code}")

            # Peque√±a pausa para no sobrecargar el servidor
            if idx < len(property_list):
                time.sleep(1)

        # Reporte final
        print("\n" + "="*80)
        print("üìä REPORTE FINAL DE DESCARGA BATCH")
        print("="*80)
        print(f"   Total Procesadas: {stats['total']}")
        print(f"   ‚úÖ Exitosas: {stats['success']}")
        print(f"   ‚ùå Fallidas: {stats['failed']}")
        print(f"   ‚ö†Ô∏è  Sin im√°genes: {stats['no_images']}")
        print(f"   üì∏ Total Im√°genes Descargadas: {stats['total_images']}")

        if stats['failed_items']:
            print(f"\nüìã Items Fallidos ({len(stats['failed_items'])}):")
            for i, item in enumerate(stats['failed_items'][:20], 1):
                print(f"   {i:2d}. {item}")
            if len(stats['failed_items']) > 20:
                print(f"   ... y {len(stats['failed_items']) - 20} m√°s")

        print("="*80)
        print("‚úÖ PROCESO COMPLETADO")
        print("="*80)

        return stats


def main():
    """Funci√≥n principal"""

    print("="*80)
    print("BATCH DOWNLOADER - DESCARGA MASIVA DE IM√ÅGENES DE PROPIEDADES")
    print("="*80)

    # Par√°metros configurables
    codes_file = "property_images/listado.txt"
    max_properties = None  # None = todas, o especificar n√∫mero
    start_from = 0  # √çndice desde donde empezar
    max_pages = 10  # N√∫mero m√°ximo de p√°ginas de b√∫squeda a navegar

    # Permitir par√°metros por l√≠nea de comandos
    if len(sys.argv) > 1:
        try:
            max_properties = int(sys.argv[1])
            print(f"üìù L√≠mite establecido: {max_properties} propiedades")
        except:
            print("üí° USO: python batch_download_from_list.py [max_propiedades] [start_from] [max_pages]")
            print("üí° EJEMPLOS:")
            print("   python batch_download_from_list.py 10")
            print("   python batch_download_from_list.py 20 0 5")
            print("   python batch_download_from_list.py")
            print()

    if len(sys.argv) > 2:
        try:
            start_from = int(sys.argv[2])
            print(f"üîÑ Iniciando desde posici√≥n: {start_from}")
        except:
            pass

    if len(sys.argv) > 3:
        try:
            max_pages = int(sys.argv[3])
            print(f"üìÑ M√°ximo de p√°ginas: {max_pages}")
        except:
            pass

    # Crear descargador
    downloader = BatchPropertyDownloader(codes_file=codes_file)

    # Procesar propiedades
    downloader.process_all_properties(
        max_properties=max_properties,
        start_from=start_from,
        max_pages=max_pages
    )


if __name__ == "__main__":
    main()
